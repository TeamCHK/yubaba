{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets[s3] \"torch==1.11\" \"transformers==4.6.1\" \"sentencepiece==0.1.96\" \"sagemaker>=2.48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b2c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq sagemaker-huggingface-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e014833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e00afffd2a343fdb76fd8d68666ddf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4f1b50c2a34eb3b9b662b47d400c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a75380ea74382b6ea80e3c862aa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9452e199ed461a94cbf91561f5c805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'restaurant design experts advised them to clear their tables of high-touch items like salt, pepper and'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\", framework=\"pt\")\n",
    "summarizer(\"Early in the pandemic, restaurants ditched physical menus and instead revived a long-sidelined technology, the quick response code. It seemed like a good idea at the time. As restaurants reopened from government-mandated Covid lockdowns, restaurant design experts advised them to clear their tables of high-touch items like salt, pepper and ketchup bottles. Even the physical menu had to go, and thus the QR code — which, when scanned, opens up a digital menu — came into vogue.\", min_length=5, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc61468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::279578104300:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n",
      "sagemaker bucket: sagemaker-us-east-1-279578104300\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {session_bucket}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72a086f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb562037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv downloaded\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "import os\n",
    "\n",
    "if (\"wikihowAll.csv\" not in os.listdir()):\n",
    "    S3Downloader.download(s3_uri=\"s3://sagemaker-us-east-1-279578104300/yubaba/dataset/wikihow/all/wikihowAll.csv\",\n",
    "                      local_path=\".\",\n",
    "                      sagemaker_session=sagemaker_session)\n",
    "    print(\"csv downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e3500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'wikihow', 'portion': 0.01, 'data_dir': '.'},\n",
       " 'tokenizer': {'max_length': 1024},\n",
       " 'model': {'name': 't5_base', 'checkpoint': None},\n",
       " 'train': {'model_path': '',\n",
       "  'checkpoint_path': '',\n",
       "  'num_epochs': 1,\n",
       "  'learning_rate': 0.0003,\n",
       "  'weight_decay': 0.001,\n",
       "  'eps': 1e-08,\n",
       "  'batch_size': 2,\n",
       "  'gradient_accum_steps': 8},\n",
       " 'eval': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"./configs/wikihow_t5.yaml\", \"r\") as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda95125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from wrapper.wikihow import Wikihow\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small', model_max_length = config[\"tokenizer\"][\"max_length\"])\n",
    "\n",
    "def tokenize(batch):\n",
    "    inputs = batch['text']\n",
    "    inputs = inputs.strip().replace(\"\\n\",\"\")\n",
    "        \n",
    "    labels = batch['headline']\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus([inputs], truncation = True, padding = \"max_length\", return_tensors = \"pt\")\n",
    "    targets = tokenizer.batch_encode_plus([labels], truncation = True, padding = \"max_length\", return_tensors = \"pt\")\n",
    "        \n",
    "    return {\"source_ids\": inputs[\"input_ids\"].squeeze(), \n",
    "            \"source_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"target_ids\": targets[\"input_ids\"].squeeze(),\n",
    "            \"target_mask\": targets[\"attention_mask\"].squeeze()}\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = load_dataset(\"wikihow\", \"all\", data_dir=\".\", split=[\"train\", \"validation\", \"test\"])\n",
    "train_dataset = train_dataset.map(tokenize, batched=False)\n",
    "validatation_dataset = validation_dataset.map(tokenize, batched=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=False)\n",
    "train_dataset.set_format('torch')\n",
    "validation_dataset.set_format('torch')\n",
    "test_dataset.set_format('torch')\n",
    "\n",
    "(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "train_input_path = f's3://{session_bucket}/yubaba/dataset/train'\n",
    "validation_input_path = f's3://{session_bucket}/yubaba/dataset/validation'\n",
    "test_input_path = f's3://{session_bucket}/yubaba/dataset/test'\n",
    "\n",
    "train_dataset.save_to_disk(train_input_path, fs=s3)\n",
    "validation_dataset.save_to_disk(validation_input_path, fs=s3)\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c12e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "train_input_path = f's3://{session_bucket}/yubaba/dataset/train'\n",
    "validation_input_path = f's3://{session_bucket}/yubaba/dataset/validation'\n",
    "test_input_path = f's3://{session_bucket}/yubaba/dataset/test'\n",
    "\n",
    "hyperparameters = {\n",
    "    \"num_epochs\": 1,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"eps\": 0.00000001,\n",
    "    \"gradient_accum_steps\": 8,\n",
    "    \"batch_size\": 2,\n",
    "    \"model_name\": \"t5-small\"\n",
    "}\n",
    "\n",
    "estimator = HuggingFace(entry_point=\"entry.py\",\n",
    "                    source_dir=\"./src\",\n",
    "                    instance_type='ml.p3.2xlarge',                    \n",
    "                    instance_count=1,                    \n",
    "                    role=role, \n",
    "                    transformers_version='4.17',\n",
    "                    py_version=\"py38\",\n",
    "                    pytorch_version=\"1.10\",\n",
    "                    hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9616059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# gets role for executing training job\n",
    "role = sagemaker.get_execution_role()\n",
    "hyperparameters = {\n",
    "\t'model_name_or_path':'t5-small',\n",
    "\t'output_dir':'/opt/ml/model'\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/seq2seq\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "\tentry_point='run_summarization.py',\n",
    "\tsource_dir='./examples/pytorch/seq2seq',\n",
    "\tinstance_type='ml.p3.2xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.17.0',\n",
    "\tpytorch_version='1.10.2',\n",
    "\tpy_version='py38',\n",
    "\thyperparameters = hyperparameters\n",
    ")\n",
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b02554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-20 22:06:48 Starting - Starting the training job...\n",
      "2022-08-20 22:07:16 Starting - Preparing the instances for trainingProfilerReport-1661033208: InProgress\n",
      ".........\n",
      "2022-08-20 22:08:41 Downloading - Downloading input data...............\n",
      "2022-08-20 22:11:12 Training - Downloading the training image............\n",
      "2022-08-20 22:13:08 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:11,723 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:11,749 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:11,755 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:12,235 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.21.0\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 59.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting torch==1.11\u001b[0m\n",
      "\u001b[34mDownloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 750.6/750.6 MB 1.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece==0.1.96 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.1.96)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.4.0\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.4.0-py3-none-any.whl (365 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 365.7/365.7 kB 30.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (2022.7.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (3.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (0.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.21.0->-r requirements.txt (line 1)) (4.63.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.11->-r requirements.txt (line 2)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.6 in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (0.3.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (8.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (1.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==2.4.0->-r requirements.txt (line 4)) (0.70.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.21.0->-r requirements.txt (line 1)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.21.0->-r requirements.txt (line 1)) (1.26.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.21.0->-r requirements.txt (line 1)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.21.0->-r requirements.txt (line 1)) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.21.0->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==2.4.0->-r requirements.txt (line 4)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==2.4.0->-r requirements.txt (line 4)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==2.4.0->-r requirements.txt (line 4)) (2022.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.4.0->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: torch, transformers, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: torch\u001b[0m\n",
      "\u001b[34mFound existing installation: torch 1.10.2+cu113\u001b[0m\n",
      "\u001b[34mUninstalling torch-1.10.2+cu113:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled torch-1.10.2+cu113\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.17.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.17.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.17.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 1.18.4\u001b[0m\n",
      "\u001b[34mUninstalling datasets-1.18.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-1.18.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed datasets-2.4.0 torch-1.11.0 transformers-4.21.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2 -> 22.2.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:57,095 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:57,095 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:13:57,171 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 2,\n",
      "        \"eps\": 1e-08,\n",
      "        \"gradient_accum_steps\": 8,\n",
      "        \"learning_rate\": 0.0003,\n",
      "        \"num_epochs\": 1,\n",
      "        \"weight_decay\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-08-20-22-06-47-955\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-279578104300/huggingface-pytorch-training-2022-08-20-22-06-47-955/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":2,\"eps\":1e-08,\"gradient_accum_steps\":8,\"learning_rate\":0.0003,\"num_epochs\":1,\"weight_decay\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-279578104300/huggingface-pytorch-training-2022-08-20-22-06-47-955/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":2,\"eps\":1e-08,\"gradient_accum_steps\":8,\"learning_rate\":0.0003,\"num_epochs\":1,\"weight_decay\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"huggingface-pytorch-training-2022-08-20-22-06-47-955\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-279578104300/huggingface-pytorch-training-2022-08-20-22-06-47-955/source/sourcedir.tar.gz\",\"module_name\":\"entry\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"2\",\"--eps\",\"1e-08\",\"--gradient_accum_steps\",\"8\",\"--learning_rate\",\"0.0003\",\"--num_epochs\",\"1\",\"--weight_decay\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_EPS=1e-08\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUM_STEPS=8\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0003\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.001\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220724-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 entry.py --batch_size 2 --eps 1e-08 --gradient_accum_steps 8 --learning_rate 0.0003 --num_epochs 1 --weight_decay 0.001\u001b[0m\n",
      "\u001b[34mDownloading config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading config.json: 100%|██████████| 1.17k/1.17k [00:00<00:00, 1.22MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   0%|          | 0.00/231M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   2%|▏         | 4.60M/231M [00:00<00:04, 48.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   4%|▍         | 9.46M/231M [00:00<00:04, 49.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   6%|▋         | 14.7M/231M [00:00<00:04, 52.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   9%|▊         | 20.2M/231M [00:00<00:04, 54.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  11%|█         | 25.4M/231M [00:00<00:03, 54.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  13%|█▎        | 30.6M/231M [00:00<00:03, 54.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  16%|█▌        | 35.8M/231M [00:00<00:03, 53.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  18%|█▊        | 41.0M/231M [00:00<00:03, 53.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  20%|█▉        | 46.1M/231M [00:00<00:03, 52.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  22%|██▏       | 51.1M/231M [00:01<00:03, 52.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  24%|██▍       | 56.3M/231M [00:01<00:03, 52.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  27%|██▋       | 61.4M/231M [00:01<00:03, 53.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  29%|██▉       | 67.8M/231M [00:01<00:02, 57.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  32%|███▏      | 74.4M/231M [00:01<00:02, 60.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  35%|███▍      | 80.2M/231M [00:01<00:02, 60.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  37%|███▋      | 86.0M/231M [00:01<00:02, 59.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  40%|███▉      | 91.8M/231M [00:01<00:02, 60.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  42%|████▏     | 98.0M/231M [00:01<00:02, 61.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  45%|████▌     | 104M/231M [00:01<00:02, 63.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  48%|████▊     | 111M/231M [00:02<00:01, 65.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  51%|█████     | 117M/231M [00:02<00:01, 64.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  53%|█████▎    | 123M/231M [00:02<00:01, 60.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  56%|█████▌    | 129M/231M [00:02<00:01, 57.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  58%|█████▊    | 135M/231M [00:02<00:01, 54.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  61%|██████    | 140M/231M [00:02<00:01, 55.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  63%|██████▎   | 146M/231M [00:02<00:01, 55.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  65%|██████▌   | 151M/231M [00:02<00:01, 54.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  68%|██████▊   | 157M/231M [00:02<00:01, 56.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  70%|███████   | 162M/231M [00:03<00:01, 55.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  72%|███████▏  | 167M/231M [00:03<00:01, 53.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  75%|███████▍  | 172M/231M [00:03<00:01, 52.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  77%|███████▋  | 177M/231M [00:03<00:01, 52.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  79%|███████▉  | 182M/231M [00:03<00:01, 48.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  81%|████████  | 187M/231M [00:03<00:00, 47.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  84%|████████▎ | 193M/231M [00:03<00:00, 51.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  86%|████████▌ | 198M/231M [00:03<00:00, 49.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  88%|████████▊ | 204M/231M [00:03<00:00, 53.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  90%|█████████ | 209M/231M [00:03<00:00, 53.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  93%|█████████▎| 214M/231M [00:04<00:00, 53.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  95%|█████████▍| 219M/231M [00:04<00:00, 53.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  97%|█████████▋| 224M/231M [00:04<00:00, 53.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  99%|█████████▉| 229M/231M [00:04<00:00, 51.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin: 100%|██████████| 231M/231M [00:04<00:00, 54.8MB/s]\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:14:14,107 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:14:14,107 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-08-20 22:14:14,107 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-08-20 22:14:43 Uploading - Uploading generated training model\n",
      "2022-08-20 22:16:44 Completed - Training job completed\n",
      "Training seconds: 488\n",
      "Billable seconds: 488\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\": train_input_path, \"test\": test_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9487875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef9fe7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"(\\\"You need to define one of the following [\\u0027audio-classification\\u0027, \\u0027automatic-speech-recognition\\u0027, \\u0027feature-extraction\\u0027, \\u0027text-classification\\u0027, \\u0027token-classification\\u0027, \\u0027question-answering\\u0027, \\u0027table-question-answering\\u0027, \\u0027fill-mask\\u0027, \\u0027summarization\\u0027, \\u0027translation\\u0027, \\u0027text2text-generation\\u0027, \\u0027text-generation\\u0027, \\u0027zero-shot-classification\\u0027, \\u0027zero-shot-image-classification\\u0027, \\u0027conversational\\u0027, \\u0027image-classification\\u0027, \\u0027image-segmentation\\u0027, \\u0027object-detection\\u0027] as env \\u0027HF_TASK\\u0027.\\\", 403)\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-training-2022-08-20-22-18-16-181 in account 279578104300 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7304/2591124170.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Early in the pandemic, restaurants ditched physical menus and instead revived a long-sidelined technology, the quick response code. It seemed like a good idea at the time. As restaurants reopened from government-mandated Covid lockdowns, restaurant design experts advised them to clear their tables of high-touch items like salt, pepper and ketchup bottles. Even the physical menu had to go, and thus the QR code — which, when scanned, opens up a digital menu — came into vogue.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m }\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 )\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"(\\\"You need to define one of the following [\\u0027audio-classification\\u0027, \\u0027automatic-speech-recognition\\u0027, \\u0027feature-extraction\\u0027, \\u0027text-classification\\u0027, \\u0027token-classification\\u0027, \\u0027question-answering\\u0027, \\u0027table-question-answering\\u0027, \\u0027fill-mask\\u0027, \\u0027summarization\\u0027, \\u0027translation\\u0027, \\u0027text2text-generation\\u0027, \\u0027text-generation\\u0027, \\u0027zero-shot-classification\\u0027, \\u0027zero-shot-image-classification\\u0027, \\u0027conversational\\u0027, \\u0027image-classification\\u0027, \\u0027image-segmentation\\u0027, \\u0027object-detection\\u0027] as env \\u0027HF_TASK\\u0027.\\\", 403)\"\n}\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/huggingface-pytorch-training-2022-08-20-22-18-16-181 in account 279578104300 for more information."
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"inputs\": \"Early in the pandemic, restaurants ditched physical menus and instead revived a long-sidelined technology, the quick response code. It seemed like a good idea at the time. As restaurants reopened from government-mandated Covid lockdowns, restaurant design experts advised them to clear their tables of high-touch items like salt, pepper and ketchup bottles. Even the physical menu had to go, and thus the QR code — which, when scanned, opens up a digital menu — came into vogue.\"\n",
    "}\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b471442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
