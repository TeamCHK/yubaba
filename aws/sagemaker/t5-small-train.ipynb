{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960107d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets[s3] \"torch==1.11\" \"transformers==4.21.0\" \"sentencepiece==0.1.96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16daea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd9c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::279578104300:role/service-role/AmazonSageMaker-ExecutionRole-20220729T235326\n",
      "sagemaker bucket: sagemaker-us-east-1-279578104300\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "session_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {session_bucket}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ad5315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv downloaded\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "import os\n",
    "\n",
    "if (\"wikihowAll.csv\" not in os.listdir()):\n",
    "    S3Downloader.download(s3_uri=\"s3://sagemaker-us-east-1-279578104300/yubaba/dataset/wikihow/all/wikihowAll.csv\",\n",
    "                      local_path=\".\",\n",
    "                      sagemaker_session=sagemaker_session)\n",
    "    print(\"csv downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132c2b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'wikihow', 'portion': 0.01, 'data_dir': '.'},\n",
       " 'tokenizer': {'max_length': 1024},\n",
       " 'model': {'name': 't5_base', 'checkpoint': None},\n",
       " 'train': {'model_path': '',\n",
       "  'checkpoint_path': '',\n",
       "  'num_epochs': 1,\n",
       "  'learning_rate': 0.0003,\n",
       "  'weight_decay': 0.001,\n",
       "  'eps': 1e-08,\n",
       "  'batch_size': 2,\n",
       "  'gradient_accum_steps': 8},\n",
       " 'eval': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"./configs/wikihow_t5.yaml\", \"r\") as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ec6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from wrapper.wikihow import Wikihow\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small', model_max_length = config[\"tokenizer\"][\"max_length\"])\n",
    "\n",
    "def tokenize(batch):\n",
    "    inputs = batch['text']\n",
    "    inputs = inputs.strip().replace(\"\\n\",\"\")\n",
    "        \n",
    "    labels = batch['headline']\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus([inputs], truncation = True, padding = \"max_length\", return_tensors = \"pt\")\n",
    "    targets = tokenizer.batch_encode_plus([labels], truncation = True, padding = \"max_length\", return_tensors = \"pt\")\n",
    "        \n",
    "    return {\"source_ids\": inputs[\"input_ids\"].squeeze(), \n",
    "            \"source_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "            \"target_ids\": targets[\"input_ids\"].squeeze(),\n",
    "            \"target_mask\": targets[\"attention_mask\"].squeeze()}\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = load_dataset(\"wikihow\", \"all\", data_dir=\".\", split=[\"train\", \"validation\", \"test\"])\n",
    "train_dataset = train_dataset.map(tokenize, batched=False)\n",
    "validatation_dataset = validation_dataset.map(tokenize, batched=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=False)\n",
    "train_dataset.set_format('torch')\n",
    "validation_dataset.set_format('torch')\n",
    "test_dataset.set_format('torch')\n",
    "\n",
    "(train_dataset, validation_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9916afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "train_input_path = f's3://{session_bucket}/yubaba/dataset/train'\n",
    "validation_input_path = f's3://{session_bucket}/yubaba/dataset/validation'\n",
    "test_input_path = f's3://{session_bucket}/yubaba/dataset/test'\n",
    "\n",
    "train_dataset.save_to_disk(train_input_path, fs=s3)\n",
    "validation_dataset.save_to_disk(validation_input_path, fs=s3)\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00e4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "train_input_path = f's3://{session_bucket}/yubaba/dataset/train'\n",
    "validation_input_path = f's3://{session_bucket}/yubaba/dataset/validation'\n",
    "test_input_path = f's3://{session_bucket}/yubaba/dataset/test'\n",
    "\n",
    "hyperparameters = {\n",
    "    \"num_epochs\": 1,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"eps\": 0.00000001,\n",
    "    \"gradient_accum_steps\": 8,\n",
    "    \"batch_size\": 2,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(entry_point=\"entry.py\",\n",
    "                    source_dir=\"./src\",\n",
    "                    role=role, \n",
    "                    py_version=\"py38\",\n",
    "                    framework_version=\"1.11.0\",\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.xlarge',\n",
    "                    hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\": train_input_path, \"test\": test_input_path})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
